{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab-02-1&2-linear_regression.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YOOOOONA/PYTORCH_zerotoall/blob/master/lab_02_1%262_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "UTkv-DFiwvzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1977
        },
        "outputId": "d8e18d3d-0c49-4ef0-f1d4-b8577a7cd01e"
      },
      "cell_type": "code",
      "source": [
        "# Lab 2 Linear Regression\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "torch.manual_seed(777)   # for reproducibility\n",
        "\n",
        "# X and Y data\n",
        "x_train = [[1], [2], [3]]\n",
        "y_train = [[1], [2], [3]]\n",
        "X = Variable(torch.Tensor(x_train))\n",
        "Y = Variable(torch.Tensor(y_train))\n",
        "\n",
        "# Our hypothesis XW+b\n",
        "model = nn.Linear(1, 1, bias=True)\n",
        "\n",
        "# cost criterion\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Minimize\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Train the model\n",
        "for step in range(2001):\n",
        "    optimizer.zero_grad()\n",
        "    # Our hypothesis\n",
        "    hypothesis = model(X)\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 20 == 0:\n",
        "        print(step, cost.data.numpy(), model.weight.data.numpy(), model.bias.data.numpy())\n",
        "\n",
        "\n",
        "# Testing our model\n",
        "predicted = model(Variable(torch.Tensor([[5]])))\n",
        "print(predicted.data.numpy())\n",
        "predicted = model(Variable(torch.Tensor([[2.5]])))\n",
        "print(predicted.data.numpy())\n",
        "predicted = model(Variable(torch.Tensor([[1.5], [3.5]])))\n",
        "print(predicted.data.numpy())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 15.86425 [[-0.66408455]] [0.05607617]\n",
            "20 0.20035125 [[0.5923785]] [0.5717581]\n",
            "40 0.053143997 [[0.7237281]] [0.5942415]\n",
            "60 0.047098298 [[0.74739474]] [0.5710139]\n",
            "80 0.042764813 [[0.7602834]] [0.5446258]\n",
            "100 0.038839594 [[0.7716461]] [0.51907295]\n",
            "120 0.035274763 [[0.7823871]] [0.49468252]\n",
            "140 0.03203709 [[0.792615]] [0.47143465]\n",
            "160 0.029096607 [[0.8023614]] [0.44927898]\n",
            "180 0.02642598 [[0.81164974]] [0.42816448]\n",
            "200 0.024000496 [[0.8205015]] [0.40804225]\n",
            "220 0.021797627 [[0.8289373]] [0.38886574]\n",
            "240 0.01979696 [[0.8369767]] [0.37059048]\n",
            "260 0.017979907 [[0.84463805]] [0.3531741]\n",
            "280 0.016329652 [[0.85193956]] [0.33657622]\n",
            "300 0.014830852 [[0.85889786]] [0.3207584]\n",
            "320 0.013469601 [[0.8655291]] [0.3056839]\n",
            "340 0.0122333225 [[0.87184876]] [0.29131788]\n",
            "360 0.011110494 [[0.8778714]] [0.27762702]\n",
            "380 0.010090737 [[0.88361096]] [0.26457956]\n",
            "400 0.009164562 [[0.8890809]] [0.2521453]\n",
            "420 0.008323396 [[0.8942937]] [0.24029532]\n",
            "440 0.007559442 [[0.89926153]] [0.2290023]\n",
            "460 0.006865607 [[0.9039958]] [0.21824004]\n",
            "480 0.006235455 [[0.90850776]] [0.20798357]\n",
            "500 0.0056631295 [[0.9128075]] [0.19820909]\n",
            "520 0.005143344 [[0.91690516]] [0.18889399]\n",
            "540 0.0046712747 [[0.92081034]] [0.18001671]\n",
            "560 0.0042425278 [[0.92453194]] [0.17155658]\n",
            "580 0.0038531402 [[0.9280788]] [0.16349408]\n",
            "600 0.0034994702 [[0.9314588]] [0.15581043]\n",
            "620 0.0031782817 [[0.9346799]] [0.14848791]\n",
            "640 0.0028865654 [[0.93774974]] [0.14150953]\n",
            "660 0.0026216197 [[0.9406753]] [0.13485906]\n",
            "680 0.0023809918 [[0.9434633]] [0.12852114]\n",
            "700 0.0021624665 [[0.9461203]] [0.12248113]\n",
            "720 0.001963982 [[0.94865245]] [0.11672498]\n",
            "740 0.0017837202 [[0.95106566]] [0.11123934]\n",
            "760 0.0016200019 [[0.9533653]] [0.10601148]\n",
            "780 0.0014713093 [[0.955557]] [0.10102937]\n",
            "800 0.0013362723 [[0.95764565]] [0.09628137]\n",
            "820 0.0012136172 [[0.9596363]] [0.09175647]\n",
            "840 0.001102231 [[0.9615332]] [0.0874442]\n",
            "860 0.0010010592 [[0.963341]] [0.08333462]\n",
            "880 0.0009091801 [[0.96506375]] [0.07941822]\n",
            "900 0.00082573376 [[0.9667057]] [0.07568585]\n",
            "920 0.00074994424 [[0.96827036]] [0.07212891]\n",
            "940 0.0006811122 [[0.9697615]] [0.06873915]\n",
            "960 0.0006185979 [[0.97118264]] [0.06550866]\n",
            "980 0.00056182063 [[0.9725369]] [0.06243001]\n",
            "1000 0.0005102526 [[0.9738276]] [0.05949603]\n",
            "1020 0.0004634207 [[0.9750576]] [0.05669993]\n",
            "1040 0.00042088534 [[0.97622985]] [0.05403522]\n",
            "1060 0.00038225626 [[0.9773469]] [0.05149576]\n",
            "1080 0.0003471718 [[0.9784115]] [0.04907567]\n",
            "1100 0.00031530656 [[0.97942615]] [0.04676931]\n",
            "1120 0.00028636312 [[0.98039305]] [0.04457127]\n",
            "1140 0.00026008004 [[0.9813145]] [0.04247656]\n",
            "1160 0.00023620897 [[0.98219264]] [0.04048032]\n",
            "1180 0.00021453059 [[0.9830295]] [0.0385779]\n",
            "1200 0.0001948383 [[0.98382705]] [0.03676487]\n",
            "1220 0.00017695712 [[0.98458713]] [0.03503707]\n",
            "1240 0.00016071474 [[0.9853115]] [0.03339045]\n",
            "1260 0.00014596382 [[0.9860018]] [0.03182122]\n",
            "1280 0.00013256578 [[0.98665965]] [0.03032574]\n",
            "1300 0.00012039869 [[0.98728657]] [0.02890054]\n",
            "1320 0.00010934887 [[0.9878841]] [0.02754232]\n",
            "1340 9.93123e-05 [[0.98845345]] [0.02624794]\n",
            "1360 9.019696e-05 [[0.9889961]] [0.02501441]\n",
            "1380 8.191908e-05 [[0.98951316]] [0.02383886]\n",
            "1400 7.4400064e-05 [[0.9900061]] [0.02271854]\n",
            "1420 6.757009e-05 [[0.99047583]] [0.02165085]\n",
            "1440 6.136819e-05 [[0.99092346]] [0.0206333]\n",
            "1460 5.573575e-05 [[0.99135]] [0.01966357]\n",
            "1480 5.062057e-05 [[0.9917565]] [0.01873944]\n",
            "1500 4.597423e-05 [[0.99214387]] [0.01785876]\n",
            "1520 4.1754534e-05 [[0.9925131]] [0.01701947]\n",
            "1540 3.7922408e-05 [[0.99286497]] [0.01621961]\n",
            "1560 3.4441568e-05 [[0.9932003]] [0.01545734]\n",
            "1580 3.1279596e-05 [[0.9935199]] [0.01473088]\n",
            "1600 2.840843e-05 [[0.9938244]] [0.01403857]\n",
            "1620 2.5801832e-05 [[0.99411464]] [0.01337879]\n",
            "1640 2.3433206e-05 [[0.9943912]] [0.01275007]\n",
            "1660 2.1282929e-05 [[0.99465483]] [0.01215087]\n",
            "1680 1.9329502e-05 [[0.994906]] [0.01157982]\n",
            "1700 1.7555647e-05 [[0.99514544]] [0.01103561]\n",
            "1720 1.5943262e-05 [[0.99537355]] [0.01051697]\n",
            "1740 1.4480425e-05 [[0.995591]] [0.0100227]\n",
            "1760 1.3151684e-05 [[0.9957982]] [0.00955167]\n",
            "1780 1.1944352e-05 [[0.99599564]] [0.0091028]\n",
            "1800 1.0848035e-05 [[0.9961838]] [0.00867503]\n",
            "1820 9.852422e-06 [[0.99636316]] [0.00826733]\n",
            "1840 8.948102e-06 [[0.99653405]] [0.00787881]\n",
            "1860 8.127165e-06 [[0.996697]] [0.00750855]\n",
            "1880 7.3810197e-06 [[0.9968523]] [0.00715565]\n",
            "1900 6.7037395e-06 [[0.99700016]] [0.00681934]\n",
            "1920 6.087879e-06 [[0.9971412]] [0.00649885]\n",
            "1940 5.5291234e-06 [[0.99727553]] [0.00619342]\n",
            "1960 5.021602e-06 [[0.9974035]] [0.00590235]\n",
            "1980 4.5606e-06 [[0.9975256]] [0.00562497]\n",
            "2000 4.142329e-06 [[0.99764186]] [0.00536061]\n",
            "[[4.99357]]\n",
            "[[2.4994652]]\n",
            "[[1.5018234]\n",
            " [3.497107 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}